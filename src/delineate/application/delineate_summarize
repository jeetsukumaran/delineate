#! /usr/bin/env python
# -*- coding: utf-8 -*-

import os
import sys
import json
import argparse
import collections
import json
import itertools
import delineate
from delineate import utility
from delineate import model

"""
Summarize DELINEATE results.
"""

__prog__ = os.path.basename(__file__)
__author__ = 'Jeet Sukumaran and Mark T. Holder'
__copyright__ = 'Copyright (C) 2019 Jeet Sukumaran and Mark T. Holder.'

def summarize_configuration(
        results_d,
        logger):
    all_lineage_labels = results_d["lineages"]
    species_constrained_lineage_map = results_d["species_constraints"]["species_constrained_lineage_map"]
    constrained_lineage_species_map = results_d["species_constraints"]["constrained_lineage_species_map"]
    species_names = sorted(species_constrained_lineage_map)
    logger.info("{} lineages defined in results file: {}".format(len(all_lineage_labels), ", ".join("'{}'".format(t) for t in sorted(all_lineage_labels))))
    num_lineages = ["({} lineages)".format(len(species_constrained_lineage_map[n])) for n in species_names]
    stbl = utility.compose_table(
            columns=[
                species_names,
                num_lineages,
                ],
            prefixes=["", ""],
            quoted=[True, False],
            is_indexed=True,
            indent="    ")
    logger.info("{} species defined in configuration constraints, with {} lineages assigned:\n{}".format(
            len(species_names),
            len(constrained_lineage_species_map),
            stbl,
            ))
    constrained_lineages = sorted(constrained_lineage_species_map.keys(), key=lambda n: (constrained_lineage_species_map[n], n))
    species_assignments = ["(SPECIES: '{}')".format(constrained_lineage_species_map[n]) for n in constrained_lineages]
    lntbl = utility.compose_table(
            columns=[
                constrained_lineages,
                species_assignments,
                ],
            prefixes=["", ""],
            quoted=[True, False],
            is_indexed=True,
            indent="    ")
    logger.info("{} out of {} lineages assigned by constraints to {} species:\n{}".format(
            len(constrained_lineages),
            len(all_lineage_labels),
            len(species_names),
            lntbl,
            ))
    unconstrained_lineages = sorted(n for n in all_lineage_labels if n not in constrained_lineage_species_map)
    lntbl = utility.compose_table(
            columns=[
                unconstrained_lineages,
                ],
            prefixes=[""],
            quoted=[True],
            is_indexed=True,
            indent="    ")
    logger.info("{} out of {} lineages not constrained by species assignments:\n{}".format(
            len(unconstrained_lineages),
            len(all_lineage_labels),
            lntbl,
            ))

def summarize_conspecificity(
        args,
        results_d,
        partitions_d,
        logger,
        ):
    try:
        all_lineage_labels = results_d["lineages"]
    except KeyError:
        all_lineage_labels = set(itertools.chain.from_iterable(partitions_d[0]["species_leafsets"]))
    species_constrained_lineage_map = results_d["species_constraints"]["species_constrained_lineage_map"]
    if not args.quiet:
        summarize_configuration(
                results_d=results_d,
                logger=logger)
    total_cumulative_probability = partitions_d[-1]["constrained_cumulative_probability"]
    if not args.quiet:
        logger.info("{} partitions found in results file, with total constrained cumulative probability of {}".format(
            len(partitions_d),
            total_cumulative_probability,
            ))
    if not args.lineage_labels:
        logger.info("No focal lineages specified for consideration")
        sys.exit(0)
    focal_lineages = args.lineage_labels
    if args.lineage_labels[0] == "-":
        if not args.quiet:
            logger.info("Reading focal lineages from standard input")
        focal_lineages = []
        for line in sys.stdin:
            if line:
                focal_lineages.append(line.strip())
    elif args.lineage_labels[0].startswith("file://"):
        fpath = os.path.expandvars(os.path.expandargs(args.lineage_labels[7:]))
        if not args.quiet:
            logger.info("Reading focal lineages from file: '{}'".format(fpath))
        focal_lineages = []
        with open(fpath) as lineagef:
            for line in lineagef:
                if line:
                    focal_lineages.append(line.strip())
    else:
        if not args.quiet:
            logger.info("Reading focal lineages from arguments")
        focal_lineages = args.lineage_labels
    if not focal_lineages:
        logger.error("ERROR: Focal lineages not defined or read in any source")
        sys.exit(1)
    focal_lineages = sorted(set(focal_lineages))
    if len(focal_lineages) == 1:
        desc_noun = "lineage"
    else:
        desc_noun = "lineages"
    if not args.quiet:
        logger.info("{} focal {} defined: {}".format(
            len(focal_lineages),
            desc_noun,
            ", ".join("'{}'".format(t) for t in focal_lineages)))
    not_found = []
    for ct in focal_lineages:
        if ct not in all_lineage_labels:
            not_found.append(ct)
    if not_found:
        logger.error("ERROR: {} of {} {} not defined in results: {}".format(
            len(not_found),
            len(focal_lineages),
            desc_noun,
            ", ".join("'{}'".format(t) for t in not_found)))
        sys.exit(1)
    conspecific_probabilities = []
    exclusive_conspecific_probabilities = []
    exclusive_new_species_probabilities = []
    new_species_probabilities = []
    existing_species_probabilities = []
    conspecifics_in_confidence_interval = 0
    conspecifics_not_in_confidence_interval = 0
    for partition_idx, partition in enumerate(partitions_d):
        is_conspecific = True
        found_in_species_label = None
        for species_label in partition["species_leafsets"]:
            species_leafset = partition["species_leafsets"][species_label]
            s = set(species_leafset)
            num_in_leafset = 0
            for ct in focal_lineages:
                if ct in s:
                    num_in_leafset += 1
            if num_in_leafset > 0 and num_in_leafset < len(focal_lineages):
                is_conspecific = False
                break
            elif num_in_leafset == len(focal_lineages):
                found_in_species_label = species_label
                break
        if is_conspecific:
            assert found_in_species_label is not None
            if len(partition["species_leafsets"][species_label]) == len(focal_lineages):
                is_exclusive = True
            else:
                is_exclusive = False
            partition_probability = partition["constrained_probability"]
            conspecific_probabilities.append(partition_probability)
            if partition["is_in_confidence_interval"]:
                conspecifics_in_confidence_interval += 1
            else:
                conspecifics_not_in_confidence_interval += 1
            if is_exclusive:
                exclusive_conspecific_probabilities.append(partition_probability)
            if found_in_species_label in species_constrained_lineage_map:
                existing_species_probabilities.append(partition_probability)
            else:
                new_species_probabilities.append(partition_probability)
                if is_exclusive:
                    exclusive_new_species_probabilities.append(partition_probability)
    marginal_probability_of_conspecificity = sum(conspecific_probabilities)
    marginal_probability_of_exclusive_conspecificity = sum(exclusive_conspecific_probabilities)
    marginal_probability_of_new_species = sum(new_species_probabilities)
    marginal_probability_of_existing_species = sum(existing_species_probabilities)
    marginal_probability_of_exclusive_new_species = sum(exclusive_new_species_probabilities)
    if not args.quiet:
        if len(focal_lineages) > 1:
            logger.info("{} out of {} partitions found with focal lineages conspecific".format(
                len(conspecific_probabilities),
                len(partitions_d),
                ))
            logger.info("Marginal constrained probability of focal lineages conspecificity: {}".format(marginal_probability_of_conspecificity))
            logger.info("Marginal constrained probability of focal lineages *exclusive* conspecificity: {}".format(marginal_probability_of_exclusive_conspecificity))
        logger.info("Marginal constrained probability of focal {} being collectively an exclusive new species: {}".format(desc_noun, marginal_probability_of_exclusive_new_species))
        logger.info("Marginal constrained probability of focal {} being collectively *part* (i.e., non-exclusively) of a new species: {}".format(desc_noun, marginal_probability_of_new_species))
        logger.info("Marginal constrained probability of focal {} being collectively *part* (i.e., non-exclusively) of a predefined species: {}".format(desc_noun, marginal_probability_of_existing_species))
        if total_cumulative_probability + 1e-8 < 1.0:
            logger.warning("WARNING: cumulative constrained probability in results file is only {}. Probability summarizations reported may not be accurate.".format(total_cumulative_probability))
    d = {
        "lineages": focal_lineages,
        "marginal_probability_of_conspecificity": marginal_probability_of_conspecificity,
        "marginal_probability_of_exclusive_conspecificity": marginal_probability_of_exclusive_conspecificity,
        "marginal_probability_of_new_species": marginal_probability_of_new_species,
        "marginal_probability_of_existing_species": marginal_probability_of_existing_species,
        "marginal_probability_of_exclusive_new_species": marginal_probability_of_exclusive_new_species,
    }
    return d

def main():
    parser = argparse.ArgumentParser(description=__doc__,
            parents=[delineate.get_metadata_parser_opts()])
    parser.add_argument("-r", "--results-file",
            action="store",
            help="Path to results data (JSON).")
    parser.add_argument("lineage_labels",
            metavar="LINEAGE",
            nargs="*",
            help="Labels of population lineages to consider as focal lineages in summarization. Specify '-' to read from standard input or 'file://' to read from file.",)
    parser.add_argument("-q", "--quiet",
            action="store_true",
            default=False,
            help="Run quietly.")
    output_options = parser.add_argument_group("Output Options")
    output_options.add_argument("-f", "--output-format",
            choices=["json", "table"],
            default="json",
            help="Format for output [default=%(default)s].")
    output_options.add_argument("-d", "--table-delimiter",
            default="\t",
            help="Column delimiter if outputting to table [default=TAB].")
    output_options.add_argument("--no-header-row",
            action="store_true",
            default=False,
            help="Suppress header row if outputting to table [default=TAB].")
    args = parser.parse_args()
    if args.describe:
        delineate.description()
        sys.exit(0)
    if args.version:
        print(delineate.name())
        sys.exit(0)
    # controller.is_quiet = getattr(args, "quiet", True)
    if args.results_file is None:
        sys.exit("Need to specify path to DELINEATE JSON-format results file")
    results_file = os.path.expanduser(os.path.expandvars(args.results_file))
    logger = utility.RunLogger(name="delineate-summarize",
            is_include_name=True,
            is_include_timestamp=False,
            log_to_stderr=True,
            stderr_logging_level=utility.logging.INFO,
            is_log_to_file=False,
            file_logging_level=utility.logging.INFO,
            )
    if not os.path.exists(results_file):
        logger.error("ERROR: File not found: '{}'".format(results_file))
        sys.exit(1)
    with open(results_file) as src:
        results_d = json.load(src)
    try:
        partitions_d = results_d["partitions"]
    except KeyError:
        logger.error("ERROR: 'partitions' key not found in results file.")
        sys.exit(1)
    if len(partitions_d) < 0:
        logger.error("ERROR: No data under 'partitions' key")
        sys.exit(1)

    summary_d = summarize_conspecificity(
            args=args,
            results_d=results_d,
            partitions_d=partitions_d,
            logger=logger,
            )
    with sys.stdout as out:
        if args.output_format == "json":
            json.dump(summary_d, out)
        elif args.output_format == "table":
            delimiter = args.table_delimiter
            header_row = []
            entry_row = []
            for field_name in summary_d:
                header_row.append(field_name)
                value = summary_d[field_name]
                if isinstance(value, list):
                    value = ", ".join(value)
                else:
                    value = str(value)
                entry_row.append(value)
            if not args.no_header_row:
                out.write("{}\n".format(delimiter.join(header_row)))
            out.write("{}\n".format(delimiter.join(entry_row)))

if __name__ == '__main__':
    main()
